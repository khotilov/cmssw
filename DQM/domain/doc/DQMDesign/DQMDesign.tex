%======================================================================
% To compile this file you have to set the .tex file path:
% setenv TEXINPUTS .:${PWD}/../../../::
%
% Use latex or pdflatex to compile.
%
% Author: C.Leonidopoulos, E. Meschi (parts stolen from N. Amapane)
% $Date: 2005/05/24 12:55:47 $  $Revision: 1.5 $
%
%======================================================================
\documentclass[a4paper]{cmspaper}
\usepackage{lineno} % line numbering for draft
\usepackage{ifthen}

%======================================================================
% Check for PDFLaTeX/LaTeX 

\newif\ifpdf
\ifx\pdfoutput\undefined
\pdffalse 
\else
\pdfoutput=1 
\pdftrue
\fi

\ifpdf  % ============== we are running PDFLaTeX
\usepackage{color}
\usepackage[pdftex]{graphicx,graphics}
\usepackage{epsfig}
\usepackage{pdflscape}
\usepackage[bookmarksnumbered,bookmarksopen,bookmarksopenlevel=1,
              colorlinks,
              linkcolor=blue,                      
              citecolor=blue, 
              urlcolor=blue]{hyperref}                                 
\pdfinfo{
  /Title  (Design and Operation of the DQM Infrastructure)
  /Author (...)
  /Keywords (DQM, Online, DAQ, CMS)
  }

\DeclareGraphicsExtensions{.pdf}

\else   % ============== we are not running PDFLaTeX
\usepackage{epsfig}
\usepackage{lscape}

\special{!userdict begin /bop-hook{gsave 200 30 translate
         65 rotate /Times-Roman findfont 216 scalefont setfont
         0 0 moveto 0.93 setgray (DRAFT) show grestore} def end}

\DeclareGraphicsExtensions{.eps}

%fake pdflatex commands.
\newcommand{\pdfbookmark}[3][1]{}
\newcommand{\href}[2]{#2}

\fi

%==============================================================================


\newcommand {\ie}{\mbox{\sl i.e. }}     %i.e.
\newcommand {\eg}{\mbox{\sl e.g. }}     %e.g.


\begin{document}

%==============================================================================
% title page for few authors

\begin{titlepage}

% select one of the following and type in the proper number:
%   \cmsnote{2005/000}
  \cmsnote{2007/XYZ}
%  \conferencereport{2005/000}
   \date{\today}
\smallskip
\smallskip
 \rightline{\bf Version 1.0}


  \title{Design and Operation of the CMS Physics and Data Quality
Monitoring Infrastructure}

  \begin{Authlist}
    C.~Leonidopoulos, E.~Meschi, I.~Segoni and D.~Tsirigkas
       \Instfoot{cern}{CERN, Geneva, Switzerland}
    G.~Eulisse
       \Instfoot{nort}{Northeastern University, Somewhere-In-The-States, USA}
  \end{Authlist}

% if needed, use the following:
%\collaboration{Flying Saucers Investigation Group}
%\collaboration{CMS collaboration}

  \begin{abstract}
    \pdfbookmark[1]{Abstract}{Abstract}
  This note describes the architecture and implementation of
the CMS Physics and Data Quality Monitoring infrastructure. The DQM system 
underwent its first real-life test during the CMS Magnet Test and 
Cosmic Challenge (MTCC) in 2006, where a significant fraction of
the sub-detectors composing CMS where operated together and read-out using 
final front-end electronics and the general DAQ system. Experience 
of the use of the DQM during the MTCC is reported and perspectives 
for LHC-beam operation of CMS in 2007-2008 are discussed.
  \end{abstract} 

% if needed, use the following:
%\conference{Presented at {\it Physics Rumours}, Coconut Island, April 1, 2005}
%\submitted{Submitted to {\it Physics Rumours}}
%\note{Preliminary version}
  
\end{titlepage}

\setcounter{page}{2}%JPP
\linenumbers
%==========================================
\section{Introduction} \label{sec:introduction}
%\pdfbookmark[1]{Introduction}{Introduction}
%==========================================
%
The Physics and Data Quality Monitoring system (DQM) aims at
providing a homogeneous monitoring environment across various
applications related to data taking at CMS. Its infrastructure must be fairly
flexible and easily customizable so as to be usable by different
groups across the experiment. Applications that can
benefit from a unified approach to monitoring range from the high-level
trigger algorithms in the Filter Farm to local DAQ supervision by a subdetector group
up to
off-line reconstruction jobs carrying out ``production validation''.
The primary goal of the DQM system is however to guarantee the quality of physics data
collected by the general data acquisition.

The DQM infrastructure provides a generic interface
independent of the specific technology implementation
for the  creation and update of monitoring objects (e.g. histograms),
allowing direct insertion of monitoring statements in the reconstruction code.
Producers publish a list of available information
to be delivered to consumers upon connection. They accept subscription
requests for delivery of regular updates of a given piece of information.
The DQM infrastructure provides functionality to collect and organize information received
from a number of producers, and redirect it to consumers according to their
subscription requests. This interface can be accessed from standalone
programs, or can be used from within reconstruction applications and
modules. On the client side, tools are provided for evaluating the
consistency of received information to reference information retrieved from
a database, update these references, set thresholds, raise alarms, and
create error messages for use by the central error logging facility.
%
%
%==========================================
\section{Architecture} \label{sec:architecture}
%\pdfbookmark[1]{Architecture}{Architecture}
%==========================================
%
The DQM framework is designed to deal with sets of objects (``{monitoring
elements}'', or ME) from the creation in monitoring producers (``{sources}''),
to the organization and
redistribution, on a periodical basis, in the ``{collectors},'' to their final use
by {clients}. Sources are defined as
individual nodes that have either direct access to or can process and
produce information we are interested in. The creation and update of
MEs at the source can be the result of processing input event data
(event consumers) or input monitor elements (monitor consumers).

At the other end of this architecture are the monitoring information
consumers (``{clients}''). Clients are notified of available monitoring
information (``{monitorables}'') from all sources combined. They can
subscribe to and receive periodic updates of any desired subset of the
monitorables, in a classic implementation of the ``publish-subscribe'' service.
A hierarchical system of collector nodes is responsible for
the communication between sources and clients (e.g. subscription
requests) and the actual monitoring transfer. These nodes serve as
collectors for the sources and as monitoring servers for the clients.

In order to minimize the interference with the ``main'' application
running in the source process (e.g. analysis, calibration/alignment, trigger
algorithm, etc), DQM operations at the source are reduced to a
minimum. All CPU-intensive tasks (e.g.
comparison to reference monitoring element, display, database storage,
etc.) are to be carried out at the client's side.

The above design aims at
\begin{itemize}
\item{shielding the sources from connecting clients
that could slow down the main application or threaten the stability of
the source}
\item{facilitating the quick
transfer of the monitoring information from the sources to the collectors.}
\end{itemize}
To this end, sources are connected to only 1 collector each
(but a collector can connect to multiple sources). Clients do not have
direct access to the sources. All source-client communication is carried out
through the collector (or collectors).

In this design, the production of the monitoring information is clearly
separated from the collection and the processing. The collectors act as
the ``middle man'': they are responsible for advertising the monitorables
to different clients and serve monitoring requests.
The nature of the collection and processing of the monitoring
information is statistical by construction. In particular, the DQM
\begin{itemize}
\item{is meant to help the experts identify problems that occur (and are monitored)
\emph{over a period of time} and is not expected to be capable of spotting
punctual problems}
\item{does \emph{not} give
access to particular events}
\item{does \emph{not} guarantee that two clients
will receive identical monitoring information}
\end{itemize}
%
%
%==========================================
\subsection{Components and Data Flow}\label{sec:dataflow}
%\pdfbookmark[1]{DataFlow}{DataFlow}
%==========================================
%
\label{sec:req_general}
The DQM infrastructure supports various monitorable types.
1D-, 2D- and 3D-histograms,
1D- and 2D-profiles, scalars (integer and real numbers) and string messages
can be booked and filled/updated anywhere in the
context of reconstruction and analysis code.
The infrastructure takes
care of publishing, tracking updates, and transporting these updates to
subscriber processes. The
DQM infrastructure does \emph{not} provide support for publishing/transport of individual event
data. Distribution of data to ``event consumers'' is provided by a separate
system ({\it refer to section on EventServer/EventProxy} ).
Access to booking, filling and modifying MEs is provided via abstract
interfaces in every component. MEs are organized in
%UNIX-like
directory
structures with
virtually unlimited depth, from which monitor consumers can ``pick
and choose''.
In every component, it is possible at any point in time to create
root-tuples with ``snapshots''
of the monitoring structure for debugging and reference.

\subsubsection{Sources}
\label{sec:req_sources}

Data Quality Monitoring services available to the source not only keep track of updates to
existing monitor elements, they also enable dynamic modifications to the
monitoring structure. The list of available monitoring information
can be modified at run-time by booking or deleting MEs via the public
DQM service interface.
Updated information from an individual source is distributed to all
consumers (through the collector) by an update
task (MonitorDaemon) running periodically is a separate thread of the source
process.
The interval between 2 MonitorDaemon updates,
which defines a monitoring cycle, can be configured
for each individual source process.
A ``reset'' switch can be used to specify for each ME
whether monitoring contents
should be reset at the end of a cycle\footnote{This option should be
turned on for MEs that describe dynamic content (e.g. hit
occupancy of a subdetector) and off for MEs that describe
accumulating quantities (e.g. number of events processed, number of
errors, or counters of rare events).}.

The MonitorDaemon maintains the connection with the collector and uses
the DQM service to collect updates to be transmitted to it.
The main application (which could be a critical one, like a HLT process),
is not affected by the failure of a downstream component in the DQM system
As an example, the source can continue to run even if the connection to the
collector is lost (e.g. the collector has crashed).



\subsubsection{Collectors}
\label{sec:req_collectors}

Collectors serve as dispatch points between sources and clients.
Unlike sources and clients, collectors are completely standardized and do not
need any customization.
A collector accepts network connections from sources and clients. A source
can post messages to the collector advertising available monitor contents.
All connected clients are dispatched with the entire published content available
at the collector. The collector receives subscription messages from clients
that are relayed to the appropriate sources. When a source sends an update message
containing new data, this is relayed to all subscribed clients.
Individual sources and clients can be added or removed at run-time. The collector
is responsible of keeping track of active connections.


%
%
\subsubsection{Clients}
\label{sec:req_clients}

A generic DQM client application is distinct from a source in that
it normally only deals with monitor data, and not with event data. Client input
comes in the form of updates of subscribed information from one or more collector
instances the client is connected to. As mentioned above, connections can be dropped
without affecting the overall functionality of the DQM system and its sources.
Standard components are provided that allow the client to:
\begin{itemize}
\item{start and configure itself, making connections to the relevant collector(s)}
\item{load an initial subscription list at configuration; this list can be
later edited and saved}
\item{be notified of the data taking configuration (DAQ configuration, trigger tables)
and of run start and stop}
\item{subscribe to selected subsets of data available from the connected sources}
\item{add or remove available items from the subscription list at runtime}
\item{receive and keep track of periodic updates of monitoring information from
multiple sources}
\item{collate information from different sources}
\item{maintain a local list of available data; this includes all input data, results
of collation, and all other monitor data created in the client itself}
\item{create groups of monitor elements for analysis or display}
\item{create and attach rules to monitor elements: these rules are evaluated for
each update and used for diagnostic reports}
\end{itemize}
Client applications must be customized for the use by an individual subsystem.

%
%
%
\subsubsection{Client customization}
\label{sec:dqm:tools}
%
As discussed in Section~\ref{sec:architecture}, the majority of the operations
involving MEs takes place on the client side. Here we list
a set of tools used to customize these tasks, accessible only by
clients.
\begin{itemize}
\item{Analysis tools for monitoring element operations:
``reset'', ``accumulate'', ``collate'', ``compare to reference''.}
\item{Status flags to summarize with a single discrete parameter the status of hierarchical
components of a subsystem. This is convenient for
summary pages on a GUI that can give the overall status of components
subdetector e.g. through a colour-coded system. Problem flags
can be set according to rules, alarms raised or masked.}
%
\item{Archival facility to store (and retrieve) custom sets of MEs to be
``played back'', used as reference, or for historical analysis}
%
\item{Graphical User Interface to give interactive access to
the custom operations discussed in this section via a standard set of
graphical interface widgets, and to provide visual feedback to the user (overall and
hierarchical status display, representative plots)}

\item{Display of arbitrary sets of monitor elements}

\end{itemize}
Generic graphic clients are also provided that can be connected to a
given application, 
allowing the standard DQM interface to be visualized as complex live displays of monitor
information.
%
%
%
\subsection{Control flow}

DQM applications that are part of the online systems are controlled as a
whole by a ``DQM Supervisor'' which runs under the general Run Control.
The DQM Supervisor is responsible for the central initiation of all relevant processes and the
transmission of common configuration information to them. All DQM clients implement a standardized
state machine and states are constantly reported to the supervisor
to give feedback to the shift crew in case problems are detected.
Run Control also uses the Supervisor to notify all clients when a run is started or
ended.

During the lifetime of a DQM client, interaction with the user happens through individual
application control interfaces based on the web protocol.



%==========================================
\subsection{Subdetector monitoring}\label{sec:subdetMonitoring}

Implementation of DQM tools is under active development by
the different
subdetector groups.
The current focus has been on addressing the short-term operational
needs of the Cosmic Challenge. For example,
a Drift Tubes DQM histogram browser with
a GUI based on IGUANA [insert reference here] has been used to
monitor the drift tubes as part of the commissioning effort at SX5
(Fig.~\ref{iguana-dqm}). This development will continue
on to the development of
monitoring programs
for the long-term needs of the subdetectors. A discussion of
the amount of information and resources which are necessary to monitor the operation
and performance of each subsystem is given in the subsequent subdetector chapters.
%
%

%
\begin{figure}[!htbp]
\begin{center}
\includegraphics[width=0.9\textwidth]{iguana-dqm}
\caption{Screen shot of the Drift Tubes DQM browser of online data
sources: occupancy and time boxes subscription,
            using the interactive IGUANA  GUI and tree controller to display
            several embedded ROOT canvas components. The data sources are the cosmics muons taken at SX5
during commissioning of the installed DT.\label{iguana-dqm}}
\end{center}
\end{figure}

%
%
%================
% Appendix
%================
\newpage
\appendix 
\bigskip

\section{Rationale for accessing monitoring elements via a neutral interface}
%\pdfbookmark[1]{Appendix}{Appendix}
% that does not depend on a specific implementation:
\label{app:neutral_interface}
The current implementation of the monitoring transfer mechanism from a node to
another involves {\tt ROOT} (classes {\tt TSockets}, {\tt
TServerSocket} and {\tt TMessages}). This is out of convenience, since
users have expressed the desire to be able to save monitoring
structures in root-tuples that they can access later. Since the
``behind-the-scenes'' mechanics is implemented with {\tt ROOT}, one 
would be tempted to allow users to deal directly with {\tt ROOT}
objects. However, we have made the choice to hide the ``true'' format
behind a transparent interface for both sources and clients, for a
variety of reasons:
\begin{itemize}
\item{An abstract interface does not bind the user access methods to a
specific analysis framework and/or implementation. In our particular
case, the transfer mechanism and the ``true''
ME format ({\tt ROOT}) could change in the future, without
breaking the source and client programs.}
\item{Having an abstract interface that hides the raw monitoring data from
the user is a good OO practice. The set of allowed operations on the
monitoring objects should be defined by the (abstract) user interface,
not the framework used for the implementation.}
\item{Additional functionality can be added to the monitoring objects
(\eg alarms) without directly inheriting from {\tt ROOT} classes.}
\end{itemize}


\end{document}
